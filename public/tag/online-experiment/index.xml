<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Online Experiment | Jantsje Mol</title>
    <link>https://www.jantsje.nl/tag/online-experiment/</link>
      <atom:link href="https://www.jantsje.nl/tag/online-experiment/index.xml" rel="self" type="application/rss+xml" />
    <description>Online Experiment</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Jantsje Mol Â© 2024</copyright><lastBuildDate>Thu, 14 Mar 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://www.jantsje.nl/images/icon_hu7859828887360647904.png</url>
      <title>Online Experiment</title>
      <link>https://www.jantsje.nl/tag/online-experiment/</link>
    </image>
    
    <item>
      <title>Information about changes in platform economy taxation diminishes optimism regarding future use</title>
      <link>https://www.jantsje.nl/publication/mol-molho-2024/</link>
      <pubDate>Thu, 14 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://www.jantsje.nl/publication/mol-molho-2024/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Information design in one-sided matching problems</title>
      <link>https://www.jantsje.nl/project/task-matching/</link>
      <pubDate>Wed, 06 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://www.jantsje.nl/project/task-matching/</guid>
      <description>&lt;h3&gt; For the &#39;Greater Good&#39;: Please Choose A&lt;/h3&gt; 
&lt;p&gt;With 
&lt;a href=&#34;https://www.lenkafiala.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lenka Fiala&lt;/a&gt; and 
&lt;a href=&#34;https://sites.google.com/view/sulagna/home?authuser=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sulagna Dasgupta&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Abstract:&lt;/b&gt;
How do people trade off individual versus group welfare in the face of uncertainty regarding private benefits of different actions? We propose a partial information revelation (&amp;lsquo;recommendation&amp;rsquo;) policy  designed to maximize group welfare, and we show its theoretical robustness to well-documented behavioral deviations from the risk neutral, Bayesian, and self-interested benchmark. In a large-scale online experiment with 2600 subjects, we then show that this policy fails to improve upon a full information benchmark even when individual and group objectives are aligned, as the recommended course of action is not followed often enough. In a setting where individual and group interests clash, the recommendation is followed less often, largely by subjects who misunderstand the policy. This provides suggestive evidence in favor of simplicity in information design in multi-agent strategic settings.&lt;/p&gt;
&lt;p&gt;[submitted]&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
